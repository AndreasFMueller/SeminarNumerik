%
% problemstellung.tex -- Beispiel-File für die Beschreibung des Problems
%
% (c) 2020 Prof Dr Andreas Müller, Hochschule Rapperswil
%
\section{Problemstellung
\label{ew:section:problemstellung}}
\rhead{Problemstellung}

Das Eigenwertproblem sucht die Vektoren $v_i \in \mathbb{R}^{n} $, die angewendet mit einer Matrix $\bm H$ nicht die Richtung ändern und sich dabei nur mit $\lambda_i \in \mathbb{R}$ skalieren:
\begin{equation} 
    \bm H \bm v_i = \lambda_i \bm v_i \label{ew:eq:eig}
\end{equation}

Manche Applikation benötigen nur Eigenwerte einer Matrix $\bm H(\varepsilon)$, die nur wenig von einer Matrix $\bm H_0$ mit bekannten Eigenwerten $\lambda^{(0)}$ und Eigenvektoren $\bm v^{(0)}$ abweicht.
Dies lässt sich mit der Summe
\begin{equation}
    \bm H(\varepsilon) = \bm H_0 + \varepsilon \bm H_1
\end{equation}
schreiben, wobei $\varepsilon \ll 1 $ ausdrücken soll, dass der zweite Term der Summe viel kleiner ist als $\bm H_0$.
Die Eigenwertperturbation erlaubt es, die Eigenwerte $\lambda_i(\varepsilon)$ und Eigenvektoren  $v_i(\varepsilon)$ von $\bm H$ zu approximieren.
Das Verfahren hat jedoch die Limitierung, dass die Eigenvektoren von $H_0$ zueinander othogonal sind, was für alle symetrischen $\bm H_0$ zutrifft.
Somit fassen wir zusammen,
\begin{gather*}
    \bm H(\varepsilon) = \bm H_0 + \varepsilon \bm H_1 \\
    \varepsilon \in \mathbb{R^+} \ll 1 \\
    \lambda^{(0)}, \bm v^{(0)} \quad \text{bekannt} \\
    \bm H_0 \quad \text{symetrisch}
\end{gather*} %TODO check if only H_0 must be symetric or selbstadjungiert

\section{Anwendungen}

Die allgemeine Störungstheorie kann überall angewendet werden wo ein lösbares model mit einer kleinen Wechselwirkung gesört wird.
Wie zum Beispiel, das Berechnen der Umlaufbahnen von Planeten, unter einfluss von der Anziehungskraft anderer Himmelskörpern, wobei das ungestörteungestörte Zweikörpermodell mit der Keppler-Ggleichung gelöst werden kann.  
Ein weiteres Beispiel ist das Berechnen einer Trajektorie unter Berücksichtigung der Luftfeuchtigkeit, wie es Kapitel \ref{chapter:perturbation} behandelt wird.

Eines der grössten Anwendungsgebiet der Störungstheorie von Eigenwerten, ist das Lösen der der Schrödingergleichung in der Quantenmechanik.
Dabei werden die Eigenfunktionen des Hamilton-Operators gesucht.
Aus diesem Anwendungsgebiet hat die Theorie auch ihren ursprung. %TODO check this

\section{Idee}

Die Schreibweise als Funktion von $\varepsilon$ deutet auf eine Taylorreihe hin. 
$\bm H(\varepsilon)$ kann als Taylorreihe geschrieben werden.

\begin{equation*}
    \bm H(\varepsilon) = \bm H_0 + \varepsilon \bm H_1 \GR{ + \varepsilon^2 \bm H_2  + \varepsilon^3 \bm H_3 + \dots}
\end{equation*}
Ebenso können die Eigenwerte und Eigenvektoren von $\bm H(\varepsilon)$ als Taylorreihen geschrieben werden.
\begin{align}
    \bm v_i(\varepsilon) = \bm v_{0i} + \varepsilon \bm v_{1i} \GR{ + \varepsilon^2 \bm v_{2i}  + \varepsilon^3 \bm v_{3i} + \dots} \label{ew:eq:eigvec} \\
    \lambda_i(\varepsilon) = \lambda_{0i} + \varepsilon \lambda_{1i} \GR{ + \varepsilon^2 \lambda_{2i}  + \varepsilon^3 \lambda_{3i} + \dots}  \label{ew:eq:eigval}
\end{align}
Für kleine $\varepsilon$ sollte eine Approximation erster Ordnung genügen.
Somit können alle Terme mit $\varepsilon^2$ und höher weggelassen werden.
Falls eine höhere Genauigkeit gewünscht wird, kann auch eine Methode mit einer Approximation zweiter Ordnung gewählt werden.
Diese ist jedoch aufwendiger herzuleiten und wird in diesem Paper nicht angeschaut.

Nach einsetzen der gekürzten Taylorreihen in Gleichung \ref{ew:eq:eig} erhalten wir 
\begin{align}
    \bm H(\varepsilon) \bm v_i(\varepsilon)
    &=
    \lambda_i(\varepsilon) \bm v_i(\varepsilon) \\
    (\bm H_0 + \varepsilon \bm H_1)
    (\bm v_{0i} + \varepsilon \bm v_{1i})
    &=
    (\lambda_{0i} + \varepsilon \lambda_{1i})
    (\bm v_{0i} + \varepsilon \bm v_{1i}),
\end{align}
wobei alle Variablen bekannt sind, ausser $\lambda_{1i}$ und $\bm v_{1i})$.
Die Gleichung soll nun umgeformt werden, um diese variablen zu bestimmen.

\subsection{Herleitung}

Die hier verwendete Herleitung basiert auf \cite{ew:seminar_quantenmechanik} mit ergänzungen.
Des weiteren wurde auf die in der Quantenmechanik übliche Bra-Ket-Notation verzichtet.

Als erstes wird die Gleichung ausmultipliziert und alle Terme mit $\varepsilon$ höherer Ordnung als zwei (rot markiert) werden weggelassen.
\begin{equation}
    \GN{\bm H_0 \bm v_{0i}} + 
    \varepsilon \bm H_0 \bm v_{1i} + 
    \varepsilon \bm H_1 \bm v_{0i} + 
    \RD{\varepsilon^2 \bm H_1 \bm v_{1i}}
    =
    \GN{\lambda_{0i} \bm v_{0i}} +
    \varepsilon \lambda_{0i} \bm v_{1i} +
    \varepsilon \lambda_{1i} \bm v_{0i} +
    \RD{\varepsilon^2 \lambda_{1i} \bm v_{1i}}
\end{equation}
Die grün markierten Terme entsprechen genau dem Eigenwertproblem \ref{ew:eq:eig} und können daher subtrahiert werden. Daraus erhalten wir
\begin{align}
    \varepsilon \bm H_0 \bm v_{1i} + 
    \varepsilon \bm H_1 \bm v_{0i}
    &=
    \varepsilon \lambda_{0i} \bm v_{1i} +
    \varepsilon \lambda_{1i} \bm v_{0i}
    \\
    \bm H_0 \bm v_{1i} + 
    \bm H_1 \bm v_{0i}
    &=
    \lambda_{0i} \bm v_{1i} +
    \lambda_{1i} \bm v_{0i}
\end{align}
Durch das Linksmultiplizieren mit $\bm v_{0j}^T$ können anschliessend weitere vereinfachungen gemacht werden.
\begin{equation}
    \bm v_{0j}^T \bm H_0 \bm v_{1i} + 
    \bm v_{0j}^T \bm H_1 \bm v_{0i}
    =
    \lambda_{0i} \bm v_{0j}^T \bm v_{1i} +
    \lambda_{1i} \bm v_{0j}^T \bm v_{0i}
\end{equation}
Da in den Voraussetzungen orthogonale Eigenvektoren $\bm v_{0i}$ gefordert sind, sind alle inneren Produkte
\begin{equation}
    \bm v_{0j}^T \bm v_{0i}
    =
    \delta_{ij}
    =
    \begin{cases}
        0 \quad (i \neq j),\\
        1 \quad (i = j)
    \end{cases}.
\end{equation}
%TODO wieso kann selbstadjungiert Trick angewendet werden?
Da $H_0$ selbst adjungiert ist,
\begin{equation}
    \bm v_{0j}^T \bm H_0 \bm v_{1i}
    =
    \left( \bm v_{0j}^T \bm H_0 \right) \bm v_{1i}
    =
    \bm v_{0j}^T \lambda_{0j} \bm v_{1i}
    =
    \lambda_{0j} \bm v_{0j}^T \bm v_{1i}
\end{equation}
Daher erhalten wir
\begin{equation}
    \lambda_{0j} \bm v_{0j}^T \bm v_{1i} + 
    \bm v_{0j}^T \bm H_1 \bm v_{0i}
    =
    \lambda_{0i} \bm v_{0j}^T \bm v_{1i} +
    \lambda_{1i} \delta_{ij}
\end{equation}
und ein wenig umgeformt
\begin{equation}
    \bm v_{0j}^T \bm H_1 \bm v_{0i}
    =
    \delta_{ij} \lambda_{1i} + 
    ( \lambda_{0i} - \lambda_{0j} )
    \bm v_{0j}^T  \bm v_{0i} .
\end{equation} \label{ew:eq:f}
Aus dieser Gleichung können mittels Koeffizientenvergleich zwei nützliche Formeln extrahiert werden:
\begin{alignat}{3}
    i = j \quad & \rightarrow  \quad && \lambda_{1i}&& = \bm v_{0i}^T \bm H_1 \bm v_{0i} \\
    i \neq j \quad & \rightarrow \quad && \bm v_{0j}^T \bm v_{1i}&& = \frac{\bm v_{0j}^T \bm H_1 \bm v_{0i}}{\lambda_{0i} - \lambda_{0j}}  \label{ew:eq:f2}
\end{alignat}

Die Eigenwerte $\lambda_{1i}$ können einfach in \ref{ew:eq:eigval} eingesetzt werden und liefern bereits eine fertige Formel für   
\begin{align*}
    \lambda_i(\varepsilon)
    &=
    \lambda_{0i} + \varepsilon \lambda_{1i} \\
    &=
    \lambda_{0i} + \varepsilon \bm v_{0i}^T \bm H_1 \bm v_{0i}
\end{align*}

Die Berechnung der Eigenvektoren ist etwas aufwendiger.
Die Kernidee dabei ist, dass $\bm v_{1i}$ als Summe von Abbildungen auf $\bm v_{0j}$ geschrieben werden kann
Die Eigenvektoren $\bm v_{1i}$ werden dabei mit Hilfe von Skalarprodukten $( \bm v_{0j}^T \bm v_{1i})$ in die Eigenbasis $\bm v_{0j}$ konvertiert. %TODO is that true
\begin{align*}
    \bm v_i(\varepsilon)
    &=
    \bm v_{0i} + \varepsilon \bm v_{1i} \\
    &=
    \bm v_{0i} + \varepsilon \sum_{j} ( \bm v_{0j}^T \bm v_{1i}) \, \bm v_{0j}
\end{align*}
Ein graphisches beispiel ist dieser Umwandlung ist in Abbildung \ref{ew:fig:scalar_prod} illustriert.
\begin{figure}
    \begin{center}
        \input{papers/ew/tikz/eigenvektor_abbliden.tikz.tex}
    \end{center}
    \caption[Eigenräume]{
        Beispiel einer Darstellung eines Vektors mit Abbildungen auf andere Basis.
        $v_{10}$ ist gleich der Summe der Abbildungen markiert mit rot und blau.
    } \label{ew:fig:scalar_prod}
\end{figure}
Leider stimmt formel \ref{ew:eq:f2} nur für $i \neq j$. Damit diese Formel eingesetzt werden kann, muss der fall $i = j$ aus der Summe genommen werden
\begin{align}
    \bm v_i(\varepsilon)
    &=
    \bm v_{0i} + \varepsilon ( \bm v_{0i}^T \bm v_{1i}) \bm v_{0i} + \varepsilon \sum_{j \neq i} (\bm v_{0j}^T \bm v_{1i}) \, \bm v_{0j} \\
    &=
    \bm v_{0i} ( 1 + (\bm v_{0i}^T \bm v_{1i}) ) + \varepsilon \sum_{j \neq i}
    \frac{\bm v_{0j}^T \bm H_1 \bm v_{0i}}{\lambda_{0i} - \lambda_{0j}}
    \, \bm v_{0j}
\end{align}
\RD{TODO: elaborate $ \mathrm{Im}(\varepsilon \gamma)$}
\begin{equation}
    \bm v_i(\varepsilon)
    =
    \bm v_{0i} ( 1 + \mathrm{Im}(\varepsilon \gamma) ) + \varepsilon \sum_{j \neq i}
    \frac{\bm v_{0j}^T \bm H_1 \bm v_{0i}}{\lambda_{0i} - \lambda_{0j}}
    \, \bm v_{0j}
    \quad
    \QED
    \label{ew:eq:explicit_eigvecs}
\end{equation}

% Zusammenfassend, 
% \begin{align*}
%     \lambda_i(\varepsilon)
%     &=
%     \lambda_{0i} + \varepsilon \bm v_{0i}^T \bm H_1 \bm v_{0i}\\
%     \bm v_i(\varepsilon)
%     &=
%     \lambda_{0i} + \varepsilon \bm v_{0i}^T \bm H_1 \bm v_{0i}
%     \bm v_{0i} ( 1 + \mathrm{Im}(\varepsilon \gamma) ) + \varepsilon \sum_{j \neq i}
%     \frac{\bm v_{0j}^T \bm H_1 \bm v_{0i}}{\lambda_{0i} - \lambda_{0j}}
%     \, \bm v_{0j}
% \end{align*}


\section{Entartung}

Die ebenso hergeleitete Formel \ref{ew:eq:explicit_eigvecs} für die Eigenvektoren ist nicht definiert für einen Spezialfall.
Wenn zwei Eigenwerte von $\bm H_0$ gleich lange sind, entsteht eine Division durch Null, wie rot hervorgehoben:
\begin{equation*} %TODO maybe ref to equation
    \bm v_i(\varepsilon)
    =
    \bm v_{0i} ( 1+ \mathrm{Im}(\varepsilon \gamma)) + \varepsilon \sum_{j \neq i}
    \frac{\bm v_{0j}^T \bm H_1 \bm v_{0i}}{\RD{\lambda_{0i} - \lambda_{0j}}}
    \, \bm v_{0j}
\end{equation*}
Die gleichen Eigenwerte haben zur Folge, dass die dazugehörigen Eigenvektoren nicht mehr eindeutig definiert sind.
Sie können irgendwo orthogonal auf einer Hyperebene liegen.
Es gibt also keinen Eigenvektor mehr sondern einen Eigenraum.
Mehrfache Eigenwerte werden auch entartet genannt.
Bei einer numerischen Berechnung der Eigenvektoren von entarteten Eigenwerten, wie es zum Beispiel MATLAB oder NumPy macht, wird ein Eigenvektor in diesem Eigenraum gewählt.

Durch die störung von einer Matrix $\bm H_0$, also durch Addition einer geeigneten Matrix $\varepsilon \bm H_1$, können Eigenwerte gespalten werden werden.
Als Beispiel, wenn $\varepsilon = 1$, 
\begin{align}
    \bm H_0 &= 
    \begin{pmatrix}
        1 & 0 & 0\\
        0 & 1 & 0\\
        0 & 0 & 2
    \end{pmatrix},
    \quad
    \lambda_0 = \{1, 1, 2\},
    \quad
    \bm v_0 = \{
    \begin{pmatrix}
        ?\\
        ?\\
        0
    \end{pmatrix},
    \begin{pmatrix}
        ?\\
        ?\\
        0
    \end{pmatrix},
    \begin{pmatrix}
        0\\
        0\\
        1
    \end{pmatrix}
    \}
    \\
    \bm H_1 &= 
    \begin{pmatrix}
        1 & 0 & 0\\
        0 & 2 & 0\\
        0 & 0 & 2
    \end{pmatrix},
    \quad
    \lambda_0 = \{1, 2, 2\},
    \quad
    \bm v_0 = \{
    \begin{pmatrix}
        1\\
        0\\
        0
    \end{pmatrix},
    \begin{pmatrix}
        0\\
        ?\\
        ?
    \end{pmatrix},
    \begin{pmatrix}
        0\\
        ?\\
        ?
    \end{pmatrix}
    \}
    \\
    \bm H(\varepsilon) &= 
    \begin{pmatrix}
        2 & 0 & 0\\
        0 & 3 & 0\\
        0 & 0 & 4
    \end{pmatrix},
    \quad
    \lambda_0 = \{2, 3, 4\},
    \quad
    \bm v_0 = \{
    \begin{pmatrix}
        1\\
        0\\
        0
    \end{pmatrix},
    \begin{pmatrix}
        0\\
        1\\
        0
    \end{pmatrix},
    \begin{pmatrix}
        0\\
        0\\
        1
    \end{pmatrix}
    \}.
\end{align} \label{ew:eq:entartung_bsp}
Die Dimensionen der Eigenvektoren, die einen Eigenraum bilden sind mit Fragezeichen gekennzeichnet.
Die Eigenräume der Matrizen sind in Abbildung \ref{ew:fig:entartung} illustriert.
\begin{figure}
    \begin{center}
        \input{papers/ew/tikz/entartung.tikz.tex}
    \end{center}
    \caption{Eigenräume der Beispielmatrizen von \ref{ew:eq:entartung_bsp}. }
    \label{ew:fig:entartung}
\end{figure}

Damit die Störungstheorie auch für entartete Eigenwerte funktioniert, muss das Problem mit der Division durch Null in formel \ref{ew:eq:f2} beseitigt werden.
Um dies in den Griff zu kriegen, müssen wir die Formel und Formel \label{ew:eq:f} für $i \neq j$ und $\lambda_{0i} = \lambda_{0j}$ anschauen, welche zu dieser Division durch Null geführt hatte.
Dabei erhalten wir
\begin{align}
    \bm v_{0j}^T \bm H_1 \bm v_{0i}
    &=
    \delta_{ij} \lambda_{1i} + 
    ( \lambda_{0i} - \lambda_{0j} )
    \bm v_{0j}^T  \bm v_{0i}
    \\
    \bm v_{0j}^T \bm H_1 \bm v_{0i}
    &=
    0 +
    0
    \bm v_{0j}^T  \bm v_{0i}
    = 0.
\end{align}
Falls $i, j$ entartet sind, geht die Gleichung auf. Wir können also Formel \ref{ew:eq:explicit_eigvecs} auch für entartete Eigenwerte brauchen, falls
\begin{equation}
    \bm v_{0j}^T \bm H_1 \bm v_{0i} = 0 \quad \forall \quad i,j \quad entartet.
\end{equation} \label{ew:eq:condition-degenerated}
Im Bruch mit division durch Null haben wir nun $\frac{0}{0}$.
Damit dies stimmt, müssen die Entarteten Eigenvektoren $\bm v_{0i}$ so gewählt werden, dass sie in der Eigenbasis von $\bm H_1$ stehen. %TODO elaborate section
Dazu bilden wir $\bm H_1$ auf die Basis von entarteten, zufällig gewählten Eigenvektoren ab
\begin{equation*}
    \bm H^\prime = \bm v_{0i}^T \bm H_1 \bm v_{0i} \quad \forall \quad i \quad entartet
\end{equation*}
Dadurch erhalten wir eine kleinere Matrix $\bm H^\prime$, welche nur die dimensionen des Eigenraums hat.
Von dieser müssen wir nun die Eigenvektoren finden mit dem Eigenwertproblem
\begin{equation*}
    \bm H^\prime \bm v_{i}^\prime = \lambda_{i} \bm v_i^\prime \quad \forall \quad i \quad entartet
\end{equation*}
Allerdings ist dieses problem einiges einfacher als das ursprüngliche Eigenwertproblem, da die Matrix nur die Entartungen enthält und dadurch viel kleiner ist, und die Eigenwerte $\lambda_i$ noch bekannt sind.
Die gefundenen Eigenvektoren müssen nun zurücktransformiert werden und anstelle der zufälligen Vektoren verwendet werden.
\begin{equation*}
    \bm v_{0i} \gets \bm v_{0i} \bm v_{i}^\prime \quad \forall \quad i \quad entartet
\end{equation*}

%TODO wieso genau kann summand weggelassen werden?

Zusammengefasst, auch für entartete $\lambda_0$ gilt somit
\begin{align*}
    \lambda_i(\varepsilon)
    & \gets
    \lambda_{0i} + \varepsilon \bm v_{0i}^T \bm H_1 \bm v_{0i}\\
    \bm H^\prime & \gets \bm v_{0i}^T \bm H_1 \bm v_{0i} \quad \forall \quad i \quad entartet \\
    \bm v^\prime & \gets \mathrm{Eig} \Big( \bm H^\prime \Big) \\
    \bm v_{0i} & \gets \bm v_{0i} \bm v^\prime  \quad \forall \quad i \quad entartet \\
    \bm v_i(\varepsilon)
    & \gets
        \bm v_{0i} ( 1 + \mathrm{Im}(\varepsilon \gamma) ) + \varepsilon \sum_{j \neq i, \,nicht\,entartet}
        \frac{\bm v_{0j}^T \bm H_1 \bm v_{0i}}{\lambda_{0i} - \lambda_{0j}}
        \, \bm v_{0j}.
\end{align*}
