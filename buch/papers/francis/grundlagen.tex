%
% problemstellung.tex -- Beispiel-File für die Beschreibung des Problems
%
% (c) 2020 Prof Dr Andreas Müller, Hochschule Rapperswil
%
\section{Grundlagen\label{francis:section:grundlagen}}
\rhead{Grundlagen}
Um ein besseres Verständnis für den Algorithmus zu bekommen, wollen wir zuerst einige wichtige Resultate aus der linearen Algebra in Erinnerung rufen.

\subsection{Ähnlichkeitstransformation\label{francis:section:grundlagen:aehnlichkeitstransform}}
Wird eine Matrix von rechts mit einer Matrix $C$ multipliziert und von links mit dessen Inversen, handelt es sich um eine Ähnlichkeitstransformation. 
Auch bekannt als Basiswechsel bzw. Similarity Transformation.
\begin{equation}
	\hat{A}=C^{-1}AC.
\end{equation}
Oft wird die Transformation auch in der Form $C\hat{A}=AC$ dargestellt, welche sich durch einfaches Umformen erreichen lässt.
Es handelt sich bei einer solchen Transformation lediglich um einen Wechsel des Koordinatensystems.
Daher sind einige Eigenschaften einer Matrix gegenüber einer solchen Transformation invariant.
Zueinander ähnliche Matrizen haben:
\begin{itemize}
	\item \textbf{die gleichen Eigenwerte (aber nicht notwendigerweise die gleichen Eigenvektoren)}
	\item die gleiche Determinante
	\item die gleiche Spur
	\item den gleichen Rang
	\item das gleiche Minimalpolynom
	\item die gleiche jordanische Normalform
\end{itemize}

\subsection{Spezielle Matrizen\label{francis:section:grundlagen:spezielle_matrizen}}
Im folgenden werden wir immer wieder über einige spezielle Matrixformen sprechen.
Reden wir von einer Matrix in der oberen Hessenberg Form, meinen wir eine Matrix der Form:
\begin{equation}
	\begin{bmatrix}
	* & * & * & * & * \\
	* & * & * & * & * \\
	& * & * & * & * \\
	&   & * & * & * \\
	&   &   & * & *
	\end{bmatrix}
\end{equation}
wobei, die Sterne bedeuten, dass an dieser Stelle ein Wert in der Matrix steht, welcher nicht null ist.
Die Form entspricht also fast einer oberen Dreiecksmatrix, zusätzlich sind aber alle Elemente unter der Diagonalen von null verschieden.
Im Abschnitt \ref{section:francis:vorbereitung} werden wir sehen, wie eine solche Form erreicht werden kann und wieso dies gemacht wird.
Versuchen wir eine symmetrische Matrix mit dem gleichen Algorithmus auf obere Hessenberg Form zu bringen, so entsteht ein Spezialfall, eine tridiagonale Matrix:
\begin{equation}
	\begin{bmatrix}
	* & * &   &   &   \\
	* & * & *  &   &   \\
	& * & * & * &  \\
	&   & * & * & * \\
	&   &   & * & *
	\end{bmatrix}.
\end{equation}

\subsection{Eigenwerte\label{francis:section:grundlagen:eigenwerte}}
Bei den Eigenvektoren einer Matrix handelt es sich um Vektoren, welche bei einer Multiplikation mit der Matrix nicht rotieren, sondern lediglich gestreckt werden.
Bei den jeweiligen Streckungsfaktoren handelt es sich um die dazugehörigen Eigenwerte.

Es gilt also:
\begin{equation}
	Av=\lambda w
\end{equation}
\begin{equation}
	\det(A-\lambda I) = 0
\end{equation}

Gesucht sind die Nullstellen des charakteristischen Polynoms. Da ein Polynom vom Grad n höchstens n Nullstellen hat, gibt es auch höchstens n Eigenwerte.

\begin{beispiel}
	Die Eigenwerte einer kleinen Matrix A können wie folgt berechnet werden.
	\begin{equation}
	A =
	\begin{bmatrix}
	1 & 3 & 2 \\
	0 & 2 & 1 \\
	0 & 0 & 3
	\end{bmatrix}
	\end{equation}
	
	\begin{equation}
	\det(A-\lambda I)= \det
	\begin{pmatrix}
	\begin{bmatrix}
	1-\lambda & 3 & 2 \\
	0 & 2-\lambda & 1 \\
	0 & 0 & 3-\lambda
	\end{bmatrix}
	\end{pmatrix}
	= 0
	\end{equation}
	
	daraus folgt:
	
	\begin{equation} (1-\lambda)(2-\lambda)(3-\lambda)=0\end{equation}
	und die Eigenwerte sind mit $\lambda_{1}=1$, $\lambda_{2}=2$ und $\lambda_{3}=3$ gefunden.
\end{beispiel}

Wie im Beispiel ersichtlich, sind die Eigenwerte einer Matrix in Dreiecks- oder Diagonalform durch die Diagonalelemente gegeben.
Da bei Bestimmung der Determinante (bei 3. Ordnung z. B. mit der Regel von Sarrus) alles andere verschwindet.
Kann man also eine Matrix durch verschiedene Ähnlichkeitstransformationen auf Dreiecks- bzw. Diagonalform reduzieren, oder sich deren so gut wie möglich annähern, so hat man alle Eigenwerte bzw. eine Annäherung derer berechnet.
Dieses Prinzip wird bei verschiedenen Verfahren, wie beispielsweise dem expliziten QR-Algorithmus und beim LR-Algorithmus sowie auch beim Francis Algorithmus benutzt.

\subsection{Givens Rotationen\label{francis:section:grundlagen:givens}}
Reflektoren und Rotationsmatrizen sind attraktiv, da sie einfach konstruiert werden können und mit ihnen durch eine geeignete Wahl des Rotationswinkels oder der Spiegelebene an einer gewünschten Stelle in einem Vektor eine Null erzeugt werden kann.
Dazu wird eine Rotations- bzw. Drehmatrix verwendet.
Sie hat in der Ebene die folgende Form:
\begin{equation}
	R=\begin{bmatrix}
	\cos\phi & -\sin\phi \\
	\sin\phi & \cos\phi
	\end{bmatrix}.
\end{equation}

Zur Drehung eines Punktes $P=(x,y)$ um den Winkel $\phi$ kann man einfach den dazugehörigen Ortsvektor mit der Rotationsmatrix multiplizieren und erhält so den Ortsvektor des gedrehten Punktes.
Es handelt sich dabei um eine Givens Rotationsmatrix, wenn $R^{-1}(\phi)=R_{T}(\phi)=R(-\phi)$.
Durch Erweiterung der Rotationsmatrix, können Drehungen natürlich auch in höherdimensionalem Raum verwendet werden. 

\begin{beispiel}
	Gegeben sei die Multiplikation einer Rotationsmatrix mit einem beliebigen Vektor:
	\begin{equation}
	\begin{bmatrix}
	1 & 0 & 0 & 0 & 0 & 0 \\
	0 & \cos\phi & 0 & 0 & -\sin\phi & 0 \\
	0 & 0 & 1 & 0 & 0 & 0 \\
	0 & 0 & 0 & 1 & 0 & 0 \\
	0 & \sin\phi & 0 & 0 & \cos\phi & 0 \\
	0 & 0 & 0 & 0 & 0 & 1 \\
	\end{bmatrix}
	\begin{bmatrix}
	x_{1}\\
	x_{2}\\
	x_{3}\\
	x_{4}\\
	x_{5}\\
	x_{6}\\
	\end{bmatrix}
	=
	\begin{bmatrix}
	x_{1}\\
	x_{2}\cos\phi-x_{5}\sin\phi\\
	x_{3}\\
	x_{4}\\
	x_{2}\sin\phi+x_{5}\cos\phi\\
	x_{6}\\
	\end{bmatrix}
	\end{equation}	
	
	Wie dabei zu sehen ist, werden dabei nur die 2. und 5. Reihe des Vektors verändert.
	Eine Anwendung einer solchen Rotationsmatrix entspricht also einer Rotation in jener Ebene im 6-Dimensionalen Raum, welche von Achse 2 und 5 aufgespannt wird.
	Durch eine geeignete Wahl des Rotationswinkels und ein systematisches Anwenden diverser Rotationsmatrizen kann man so einen Eintrag nach dem Andern auf Null setzen und beispielsweise eine QR-Zerlegung durchführen. \cite{francis:QR_Zerlegung}
\end{beispiel}

\subsection{Householder Transformation\label{francis:section:grundlagen:householder}}
Reflektoren sind attraktiv, da sie einfach konstruiert werden können und mit ihnen alle Elemente eines Vektors bis auf ein Element auf null gesetzt werden können.
So kann jede beliebige Matrix relativ einfach auf Hessenberg Form gebracht werden.
Ein beliebiger Vektor $x$ und ein spezieller Vektor $y$ sind gegeben.
\begin{equation}
	x=
	\begin{bmatrix}
	x_{1}\\
	x_{2}\\
	.\\
	.\\
	.\\
	x_{n}\\
	\end{bmatrix}
	,
	y=
	\begin{bmatrix}
	y_{1}\\
	0\\
	.\\
	.\\
	.\\
	0\\
	\end{bmatrix}, \text{mit } y_{1}\pm \norm{x}	
\end{equation}

Da diese beiden Vektoren dieselbe Länge haben, wissen wir, dass Reflektor $H$ existiert, sodass $Hx=y$.
Mit einem solchen Reflektor können also alle Elemente eines Vektors bis auf die ein Element auf null gesetzt werden.
\begin{equation}
	H=I-2vv^{T}, \text{mit } v=(x-y)/\norm{x-y}
\end{equation}

Das Ganze ist in Abbildung \ref{francis:abb:householder_transform} in 2D dargestellt.
\begin{figure}
	\begin{center}
		\includegraphics[scale=0.1]{papers/francis/images/Householdertransformation.png}
		\caption{Illustration der Householdertransformation in 2D, Abbildung von \cite{francis:householder}}
		\label{francis:abb:householder_transform}
	\end{center}
\end{figure}
